{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99c6c9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\llm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # This loads the variables from .env\n",
    "api_key = os.getenv('OPENAI_API_KEY')  # This gets a specific variable\n",
    "\n",
    "# Add the src directory to Python path\n",
    "src_path = \"src\"\n",
    "sys.path.append(str(src_path))\n",
    "\n",
    "from matsci_llm_causality.extraction.pdf import PDFProcessor\n",
    "from matsci_llm_causality.models import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bcf38a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize components\n",
    "pdf_processor = PDFProcessor()\n",
    "relation_extractor = create_model(\"gpt-5-relation\")\n",
    "\n",
    "# Path to your PDF\n",
    "pdf_path = Path(\"D:/Research/LLM4Causal/tests/data/sciadv.abo6043.pdf\")  # Replace with your PDF path\n",
    "text_path = Path(\"tests/data/text.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1d48805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Modern genomics combined with advanced bioinformatics methodologies allow us to understand much more about complex living systems than was ever previously possible. In the realm of human biology, for instance, recent developments have given us the ability to pinpoint the genes influencing diseases such as cancers. One area where these novel technologies can be anticipated to exert a huge impact but have thus far remained underused is the study of structural biomaterials. Spider silk is a prime example of an extended phenotype, whose extraordinary mechanical properties are governed by the underlying composition and structure of protein building blocks called spidroins.', 'All spiders use silk for various critical purposes, including foraging, locomotion, nesting, mating, egg protection, and communication  (1) . Different types of threads are used for diverse purposes, each produced in specific glands in the abdomen  (2) . For example, orb-weaving spiders use up to seven different types of silks, named after the gland that produces these threads. Major ampullate silk is the toughest silk used as draglines and as frames of orb webs, minor ampullate silk is used as scaffold during orb web weaving, piriform silk adheres the frame of the orb web to wood or other substrates, and capture thread of the orb web is composed of flagelliform silk backbone and aggregate glue. Aciniform silk is used for prey wrapping and sometimes for decorations of the web, and tubiform (or cylindrical) silk is used to make an egg sac. While spiders are successful predators and are often associated with orb webs, orb-weaving spiders of superfamily Araneoidea only comprise about 25% of spider species. A more ancestral clade of spiders such as those belonging to the infraorder Mygalomorphae is comprised mostly of ground-wandering spiders that produce sheet and maze webs for prey capture. Wandering hunters and abandoned silk capture webs make up a more modern clade of spiders in the retrolateral tibial apophysis (RTA) clade; this group comprises as much as 50% of all spider species  (3) . Therefore, spiders have diversified, selected, and specialized various uses of silk adapting to their ecological needs. Such extraordinary plasticity and university of silk and silk proteins is an ideal target to model the link between sequence and its physical property to fully understand the underlying design principles to apply the wide range of physical properties as biomaterials.', 'Spider silks are renowned for their diverse and impressive mechanical properties, frequently displaying a combination of high tensile strength, extensibility, and exceptional toughness that is unmatched industrially. Hence, the processing-property space that these silks occupy makes them a unique source of inspiration for protein biopolymer materials with low embodied energy and high performance  (4) (5) (6) . However, this property space has yet to be fully explored, defined, and exploited. Silk fiber diversity scales rapidly, as spiders produce multiple types of silk, each of which are composed of specific proteins known as spidroins, whose mostly monophyletic origins  (7)  endow them with specific mechanical properties  (2, 8) . One type of spider silk protein, major ampullate spidroin (MaSp; which is often included in dragline threads), has received substantial academic and industrial attention, as this silk typically shows strength and toughness comparable to those of synthetic high-performance fibers, with an approximately 1-GPa breaking strength, a 30% breaking strain, and a toughness of 130 to 200 MJ/m 3  (9) (10) (11) . However, there are lesser-known taxa and species of spiders, suggesting that the limits of silk properties are yet to be defined  (12) . On the other hand, a unique property known as supercontraction, where the dragline silk shrinks in length by up to 60% when wetted, is often considered undesirable industrially, and expectations are high for protein engineering methods to reduce such property by modifying the primary sequence. Hence, a comprehensive, coordinated global effort combining taxonomy, genomics, and materiomics is required to first understand and then unlock the true potential of these materials  (13) .']\n"
     ]
    }
   ],
   "source": [
    "with open(text_path, 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "paragraphs = [p.strip() for p in content.split(\"\\n\\n\") if p.strip()]\n",
    "\n",
    "print(paragraphs[:3])  # show first 3 paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1680d8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "def parse_relationships(text: str):\n",
    "    # Split text into lines, stripping empty ones\n",
    "    lines = [line.strip() for line in text.split(\"\\n\") if line.strip()]\n",
    "    \n",
    "    results = []\n",
    "    for line in lines:\n",
    "        # Regex to capture: [SubjectName][Type] relationship [ObjectName][Type]\n",
    "        match = re.match(r\"(.+?)\\[(.*?)\\]\\s+(increases|decreases|positively correlate with|negatively correlate with|causes)\\s+(.+?)\\[(.*?)\\]$\", line)\n",
    "        if match:\n",
    "            subject_name, subject_type, relation, object_name, object_type = match.groups()\n",
    "            results.append({\n",
    "                \"subject\": {\"name\": subject_name.strip(), \"type\": subject_type.strip()},\n",
    "                \"relationship\": relation.strip(),\n",
    "                \"object\": {\"name\": object_name.strip(), \"type\": object_type.strip()}\n",
    "            })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb7ec0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing paragraphs...\n",
      "\n",
      "Processing paragraph 1/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 2/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 2/43\n",
      "Found 14 relationships\n",
      "\n",
      "Processing paragraph 3/43\n",
      "Found 14 relationships\n",
      "\n",
      "Processing paragraph 3/43\n",
      "Found 4 relationships\n",
      "\n",
      "Processing paragraph 4/43\n",
      "Found 4 relationships\n",
      "\n",
      "Processing paragraph 4/43\n",
      "Found 6 relationships\n",
      "\n",
      "Processing paragraph 5/43\n",
      "Found 6 relationships\n",
      "\n",
      "Processing paragraph 5/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 6/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 6/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 7/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 7/43\n",
      "Found 1 relationships\n",
      "\n",
      "Processing paragraph 8/43\n",
      "Found 1 relationships\n",
      "\n",
      "Processing paragraph 8/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 9/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 9/43\n",
      "Found 1 relationships\n",
      "\n",
      "Processing paragraph 10/43\n",
      "Found 1 relationships\n",
      "\n",
      "Processing paragraph 10/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 11/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 11/43\n",
      "Found 3 relationships\n",
      "\n",
      "Processing paragraph 12/43\n",
      "Found 3 relationships\n",
      "\n",
      "Processing paragraph 12/43\n",
      "Found 1 relationships\n",
      "\n",
      "Processing paragraph 13/43\n",
      "Found 1 relationships\n",
      "\n",
      "Processing paragraph 13/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 14/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 14/43\n",
      "Found 5 relationships\n",
      "\n",
      "Processing paragraph 15/43\n",
      "Found 5 relationships\n",
      "\n",
      "Processing paragraph 15/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 16/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 16/43\n",
      "Found 6 relationships\n",
      "\n",
      "Processing paragraph 17/43\n",
      "Found 6 relationships\n",
      "\n",
      "Processing paragraph 17/43\n",
      "Found 10 relationships\n",
      "\n",
      "Processing paragraph 18/43\n",
      "Found 10 relationships\n",
      "\n",
      "Processing paragraph 18/43\n",
      "Found 14 relationships\n",
      "\n",
      "Processing paragraph 19/43\n",
      "Found 14 relationships\n",
      "\n",
      "Processing paragraph 19/43\n",
      "Found 6 relationships\n",
      "\n",
      "Processing paragraph 20/43\n",
      "Found 6 relationships\n",
      "\n",
      "Processing paragraph 20/43\n",
      "Found 1 relationships\n",
      "\n",
      "Processing paragraph 21/43\n",
      "Found 1 relationships\n",
      "\n",
      "Processing paragraph 21/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 22/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 22/43\n",
      "Found 1 relationships\n",
      "\n",
      "Processing paragraph 23/43\n",
      "Found 1 relationships\n",
      "\n",
      "Processing paragraph 23/43\n",
      "Found 2 relationships\n",
      "\n",
      "Processing paragraph 24/43\n",
      "Found 2 relationships\n",
      "\n",
      "Processing paragraph 24/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 25/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 25/43\n",
      "Found 1 relationships\n",
      "\n",
      "Processing paragraph 26/43\n",
      "Found 1 relationships\n",
      "\n",
      "Processing paragraph 26/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 27/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 27/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 28/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 28/43\n",
      "Found 4 relationships\n",
      "\n",
      "Processing paragraph 29/43\n",
      "Found 4 relationships\n",
      "\n",
      "Processing paragraph 29/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 30/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 30/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 31/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 31/43\n",
      "Found 3 relationships\n",
      "\n",
      "Processing paragraph 32/43\n",
      "Found 3 relationships\n",
      "\n",
      "Processing paragraph 32/43\n",
      "Found 2 relationships\n",
      "\n",
      "Processing paragraph 33/43\n",
      "Found 2 relationships\n",
      "\n",
      "Processing paragraph 33/43\n",
      "Found 2 relationships\n",
      "\n",
      "Processing paragraph 34/43\n",
      "Found 2 relationships\n",
      "\n",
      "Processing paragraph 34/43\n",
      "Found 1 relationships\n",
      "\n",
      "Processing paragraph 35/43\n",
      "Found 1 relationships\n",
      "\n",
      "Processing paragraph 35/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 36/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 36/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 37/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 37/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 38/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 38/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 39/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 39/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 40/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 40/43\n",
      "Found 1 relationships\n",
      "\n",
      "Processing paragraph 41/43\n",
      "Found 1 relationships\n",
      "\n",
      "Processing paragraph 41/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 42/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 42/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 43/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Processing paragraph 43/43\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Extraction complete!\n",
      "Total relationships found: 89\n",
      "Total unique entities found: 119\n",
      "No relationships found in this paragraph\n",
      "\n",
      "Extraction complete!\n",
      "Total relationships found: 89\n",
      "Total unique entities found: 119\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store all relationships and entities\n",
    "all_relationships = []\n",
    "all_entities = set()  # Using a set to avoid duplicates\n",
    "\n",
    "# Process each paragraph\n",
    "print(\"Processing paragraphs...\")\n",
    "for i, paragraph in enumerate(paragraphs):\n",
    "    print(f\"\\nProcessing paragraph {i+1}/{len(paragraphs)}\")\n",
    "    \n",
    "    # Extract relationships using GPT-5\n",
    "    result = relation_extractor.extract_relations(paragraph)\n",
    "    \n",
    "    # Parse the relationships from the raw text output\n",
    "    parsed_rels = parse_relationships(result)\n",
    "    \n",
    "    # Add relationships to our list\n",
    "    all_relationships.extend(parsed_rels)\n",
    "    \n",
    "    # Extract entities from relationships and add to set\n",
    "    for rel in parsed_rels:\n",
    "        # Add subject entity\n",
    "        all_entities.add(f\"{rel['subject']['name']}|{rel['subject']['type']}\")\n",
    "        # Add object entity\n",
    "        all_entities.add(f\"{rel['object']['name']}|{rel['object']['type']}\")\n",
    "    \n",
    "    # Print progress\n",
    "    if parsed_rels:\n",
    "        print(f\"Found {len(parsed_rels)} relationships\")\n",
    "    else:\n",
    "        print(\"No relationships found in this paragraph\")\n",
    "\n",
    "# Convert entity strings back to dictionary format\n",
    "all_entities = [\n",
    "    {\n",
    "        \"name\": entity.split(\"|\")[0],\n",
    "        \"type\": entity.split(\"|\")[1]\n",
    "    }\n",
    "    for entity in all_entities\n",
    "]\n",
    "\n",
    "print(f\"\\nExtraction complete!\")\n",
    "print(f\"Total relationships found: {len(all_relationships)}\")\n",
    "print(f\"Total unique entities found: {len(all_entities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df6d1327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files saved successfully with complete data structures!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save entities to JSON file with complete information\n",
    "with open('entities.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_entities, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# Save relationships to JSON file with complete information\n",
    "with open('relationships.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_relationships, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"\\nFiles saved successfully with complete data structures!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
